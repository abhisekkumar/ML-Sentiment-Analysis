{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abhis\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import tarfile\n",
    "import collections\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.1\n",
      "2.1.2\n",
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "print(mp.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_FILENAME = 'ImdbReviews.tar.gz'\n",
    "\n",
    "def download_file(url_path):\n",
    "    if not os.path.exists(DOWNLOAD_FILENAME):\n",
    "        filename, _ = urllib.request.urlretrieve(url_path, DOWNLOAD_FILENAME)\n",
    "    \n",
    "    print('Found and verified file from this path: ', url_path)\n",
    "    print('Download file: ', DOWNLOAD_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_REGEX = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def get_reviews(dirname, positive=True):\n",
    "    label = 1 if positive else 0\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(dirname):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(dirname + filename, 'r+', encoding = 'utf-8') as f:\n",
    "                review = f.read()\n",
    "                review = review.lower().replace(\"<br />\", \" \")\n",
    "                review = re.sub(TOKEN_REGEX, '', review)\n",
    "                \n",
    "                #return a tuple of review text and a label for if its a positive or negative\n",
    "                \n",
    "                reviews.append(review)\n",
    "                labels.append(label)\n",
    "    return reviews, labels\n",
    "\n",
    "def extract_labels_data():\n",
    "    #extract file if it's not performed previously\n",
    "    if not os.path.exists('aclImdb'):\n",
    "        with tarfile.open(DOWNLOAD_FILENAME) as tar:\n",
    "            tar.extractall()\n",
    "            tar.close()\n",
    "    \n",
    "    positive_reviews, positive_labels = get_reviews(\"aclImdb/train/pos/\", positive = True)\n",
    "    negative_reviews, negative_labels = get_reviews(\"aclImdb/train/neg/\", positive = False)\n",
    "    \n",
    "    data = positive_reviews + negative_reviews\n",
    "    labels = positive_labels + negative_labels\n",
    "    \n",
    "    return labels, data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified file from this path:  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Download file:  ImdbReviews.tar.gz\n"
     ]
    }
   ],
   "source": [
    "URL_PATH = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "\n",
    "download_file(URL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, data = extract_labels_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell highs satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled  at  high a classic line inspector im here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isnt',\n",
       " 'homelessness or houselessness as george carlin stated has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school work or vote for the matter most people think of the homeless as just a lost cause while worrying about things such as racism the war on iraq pressuring kids to succeed technology the elections inflation or worrying if theyll be next to end up on the streets  but what if you were given a bet to live on the streets for a month without the luxuries you once had from a home the entertainment sets a bathroom pictures on the wall a computer and everything you once treasure to see what its like to be homeless that is goddard bolts lesson  mel brooks who directs who stars as bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival jeffery tambor to see if he can live in the streets for thirty days without the luxuries if bolt succeeds he can do what he wants with a future project of making more buildings the bets on where bolt is thrown on the street with a bracelet on his leg to monitor his every move where he cant step off the sidewalk hes given the nickname pepto by a vagrant after its written on his forehead where bolt meets other characters including a woman by the name of molly lesley ann warren an exdancer who got divorce before losing her home and her pals sailor howard morris and fumes teddy wilson who are already used to the streets theyre survivors bolt isnt hes not used to reaching mutual agreements like he once did when being rich where its fight or flight kill or be killed  while the love connection between molly and bolt wasnt necessary to plot i found life stinks to be one of mel brooks observant films where prior to being a comedy it shows a tender side compared to his slapstick work such as blazing saddles young frankenstein or spaceballs for the matter to show what its like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they dont know what to do with their money maybe they should give it to the homeless instead of using it like monopoly money  or maybe this film will inspire you to help others',\n",
       " 'brilliant overacting by lesley ann warren best dramatic hobo lady i have ever seen and love scenes in clothes warehouse are second to none the corn on face is a classic as good as anything in blazing saddles the take on lawyers is also superb after being accused of being a turncoat selling out his boss and being dishonest the lawyer of pepto bolt shrugs indifferently im a lawyer he says three funny words jeffrey tambor a favorite from the later larry sanders show is fantastic here too as a mad millionaire who wants to crush the ghetto his character is more malevolent than usual the hospital scene and the scene where the homeless invade a demolition site are alltime classics look for the legs scene and the two big diggers fighting one bleeds this movie gets better each time i see it which is quite often',\n",
       " 'this is easily the most underrated film inn the brooks cannon sure its flawed it does not give a realistic view of homelessness unlike say how citizen kane gave a realistic view of lounge singers or titanic gave a realistic view of italians you idiots many of the jokes fall flat but still this film is very lovable in a way many comedies are not and to pull that off in a story about some of the most traditionally reviled members of society is truly impressive its not the fisher king but its not crap either my only complaint is that brooks should have cast someone else in the lead i love mel as a director and writer not so much as a lead',\n",
       " 'this is not the typical mel brooks film it was much less slapstick than most of his movies and actually had a plot that was followable leslie ann warren made the movie she is such a fantastic underrated actress there were some moments that could have been fleshed out a bit more and some scenes that could probably have been cut to make the room to do so but all in all this is worth the price to rent and see it the acting was good overall brooks himself did a good job without his characteristic speaking to directly to the audience again warren was the best actor in the movie but fume and sailor both played their parts well']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2470\n"
     ]
    }
   ],
   "source": [
    "max_document_length = max([len(x.split(\" \")) for x in data])\n",
    "print(max_document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.load('wordsList.npy')\n",
    "words =[word.decode('UTF-8') for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0', ',', '.', 'of', 'to'], 400000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5], len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index_dictionary(words):\n",
    "    dictionary = {}\n",
    "    \n",
    "    index = 0\n",
    "    for word in words:\n",
    "        dictionary[word] = index\n",
    "        index += 1\n",
    "        \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = get_word_index_dictionary(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 37, 600, 1399)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['and'], dictionary['this'], dictionary['together'], dictionary['supreme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_ids = []\n",
    "\n",
    "def convert_reviews_to_ids(data, words):\n",
    "    #words_list = words.tolist()\n",
    "    \n",
    "    progress = 0\n",
    "    for review in data:\n",
    "        review_id = []\n",
    "        \n",
    "        index = 0\n",
    "        for word in review:\n",
    "            if index >= MAX_SEQUENCE_LENGTH:\n",
    "                break;\n",
    "            \n",
    "            try:\n",
    "                review_id.append(dictionary[word])\n",
    "            except KeyError:\n",
    "                review_id.append(0)\n",
    "                \n",
    "            index += 1\n",
    "        \n",
    "        \n",
    "        if len(review_id) < MAX_SEQUENCE_LENGTH:\n",
    "            review_id = np.pad(review_id, (0, MAX_SEQUENCE_LENGTH - index), 'constant')\n",
    "            \n",
    "        review_ids.append(np.array(review_id))\n",
    "        progress += 1\n",
    "        \n",
    "        if progress % 100 == 0:\n",
    "            print(\"Completed: \", progress)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed:  100\n",
      "Completed:  200\n",
      "Completed:  300\n",
      "Completed:  400\n",
      "Completed:  500\n",
      "Completed:  600\n",
      "Completed:  700\n",
      "Completed:  800\n",
      "Completed:  900\n",
      "Completed:  1000\n",
      "Completed:  1100\n",
      "Completed:  1200\n",
      "Completed:  1300\n",
      "Completed:  1400\n",
      "Completed:  1500\n",
      "Completed:  1600\n",
      "Completed:  1700\n",
      "Completed:  1800\n",
      "Completed:  1900\n",
      "Completed:  2000\n",
      "Completed:  2100\n",
      "Completed:  2200\n",
      "Completed:  2300\n",
      "Completed:  2400\n",
      "Completed:  2500\n",
      "Completed:  2600\n",
      "Completed:  2700\n",
      "Completed:  2800\n",
      "Completed:  2900\n",
      "Completed:  3000\n",
      "Completed:  3100\n",
      "Completed:  3200\n",
      "Completed:  3300\n",
      "Completed:  3400\n",
      "Completed:  3500\n",
      "Completed:  3600\n",
      "Completed:  3700\n",
      "Completed:  3800\n",
      "Completed:  3900\n",
      "Completed:  4000\n",
      "Completed:  4100\n",
      "Completed:  4200\n",
      "Completed:  4300\n",
      "Completed:  4400\n",
      "Completed:  4500\n",
      "Completed:  4600\n",
      "Completed:  4700\n",
      "Completed:  4800\n",
      "Completed:  4900\n",
      "Completed:  5000\n",
      "Completed:  5100\n",
      "Completed:  5200\n",
      "Completed:  5300\n",
      "Completed:  5400\n",
      "Completed:  5500\n",
      "Completed:  5600\n",
      "Completed:  5700\n",
      "Completed:  5800\n",
      "Completed:  5900\n",
      "Completed:  6000\n",
      "Completed:  6100\n",
      "Completed:  6200\n",
      "Completed:  6300\n",
      "Completed:  6400\n",
      "Completed:  6500\n",
      "Completed:  6600\n",
      "Completed:  6700\n",
      "Completed:  6800\n",
      "Completed:  6900\n",
      "Completed:  7000\n",
      "Completed:  7100\n",
      "Completed:  7200\n",
      "Completed:  7300\n",
      "Completed:  7400\n",
      "Completed:  7500\n",
      "Completed:  7600\n",
      "Completed:  7700\n",
      "Completed:  7800\n",
      "Completed:  7900\n",
      "Completed:  8000\n",
      "Completed:  8100\n",
      "Completed:  8200\n",
      "Completed:  8300\n",
      "Completed:  8400\n",
      "Completed:  8500\n",
      "Completed:  8600\n",
      "Completed:  8700\n",
      "Completed:  8800\n",
      "Completed:  8900\n",
      "Completed:  9000\n",
      "Completed:  9100\n",
      "Completed:  9200\n",
      "Completed:  9300\n",
      "Completed:  9400\n",
      "Completed:  9500\n",
      "Completed:  9600\n",
      "Completed:  9700\n",
      "Completed:  9800\n",
      "Completed:  9900\n",
      "Completed:  10000\n",
      "Completed:  10100\n",
      "Completed:  10200\n",
      "Completed:  10300\n",
      "Completed:  10400\n",
      "Completed:  10500\n",
      "Completed:  10600\n",
      "Completed:  10700\n",
      "Completed:  10800\n",
      "Completed:  10900\n",
      "Completed:  11000\n",
      "Completed:  11100\n",
      "Completed:  11200\n",
      "Completed:  11300\n",
      "Completed:  11400\n",
      "Completed:  11500\n",
      "Completed:  11600\n",
      "Completed:  11700\n",
      "Completed:  11800\n",
      "Completed:  11900\n",
      "Completed:  12000\n",
      "Completed:  12100\n",
      "Completed:  12200\n",
      "Completed:  12300\n",
      "Completed:  12400\n",
      "Completed:  12500\n",
      "Completed:  12600\n",
      "Completed:  12700\n",
      "Completed:  12800\n",
      "Completed:  12900\n",
      "Completed:  13000\n",
      "Completed:  13100\n",
      "Completed:  13200\n",
      "Completed:  13300\n",
      "Completed:  13400\n",
      "Completed:  13500\n",
      "Completed:  13600\n",
      "Completed:  13700\n",
      "Completed:  13800\n",
      "Completed:  13900\n",
      "Completed:  14000\n",
      "Completed:  14100\n",
      "Completed:  14200\n",
      "Completed:  14300\n",
      "Completed:  14400\n",
      "Completed:  14500\n",
      "Completed:  14600\n",
      "Completed:  14700\n",
      "Completed:  14800\n",
      "Completed:  14900\n",
      "Completed:  15000\n",
      "Completed:  15100\n",
      "Completed:  15200\n",
      "Completed:  15300\n",
      "Completed:  15400\n",
      "Completed:  15500\n",
      "Completed:  15600\n",
      "Completed:  15700\n",
      "Completed:  15800\n",
      "Completed:  15900\n",
      "Completed:  16000\n",
      "Completed:  16100\n",
      "Completed:  16200\n",
      "Completed:  16300\n",
      "Completed:  16400\n",
      "Completed:  16500\n",
      "Completed:  16600\n",
      "Completed:  16700\n",
      "Completed:  16800\n",
      "Completed:  16900\n",
      "Completed:  17000\n",
      "Completed:  17100\n",
      "Completed:  17200\n",
      "Completed:  17300\n",
      "Completed:  17400\n",
      "Completed:  17500\n",
      "Completed:  17600\n",
      "Completed:  17700\n",
      "Completed:  17800\n",
      "Completed:  17900\n",
      "Completed:  18000\n",
      "Completed:  18100\n",
      "Completed:  18200\n",
      "Completed:  18300\n",
      "Completed:  18400\n",
      "Completed:  18500\n",
      "Completed:  18600\n",
      "Completed:  18700\n",
      "Completed:  18800\n",
      "Completed:  18900\n",
      "Completed:  19000\n",
      "Completed:  19100\n",
      "Completed:  19200\n",
      "Completed:  19300\n",
      "Completed:  19400\n",
      "Completed:  19500\n",
      "Completed:  19600\n",
      "Completed:  19700\n",
      "Completed:  19800\n",
      "Completed:  19900\n",
      "Completed:  20000\n",
      "Completed:  20100\n",
      "Completed:  20200\n",
      "Completed:  20300\n",
      "Completed:  20400\n",
      "Completed:  20500\n",
      "Completed:  20600\n",
      "Completed:  20700\n",
      "Completed:  20800\n",
      "Completed:  20900\n",
      "Completed:  21000\n",
      "Completed:  21100\n",
      "Completed:  21200\n",
      "Completed:  21300\n",
      "Completed:  21400\n",
      "Completed:  21500\n",
      "Completed:  21600\n",
      "Completed:  21700\n",
      "Completed:  21800\n",
      "Completed:  21900\n",
      "Completed:  22000\n",
      "Completed:  22100\n",
      "Completed:  22200\n",
      "Completed:  22300\n",
      "Completed:  22400\n",
      "Completed:  22500\n",
      "Completed:  22600\n",
      "Completed:  22700\n",
      "Completed:  22800\n",
      "Completed:  22900\n",
      "Completed:  23000\n",
      "Completed:  23100\n",
      "Completed:  23200\n",
      "Completed:  23300\n",
      "Completed:  23400\n",
      "Completed:  23500\n",
      "Completed:  23600\n",
      "Completed:  23700\n",
      "Completed:  23800\n",
      "Completed:  23900\n",
      "Completed:  24000\n",
      "Completed:  24100\n",
      "Completed:  24200\n",
      "Completed:  24300\n",
      "Completed:  24400\n",
      "Completed:  24500\n",
      "Completed:  24600\n",
      "Completed:  24700\n",
      "Completed:  24800\n",
      "Completed:  24900\n",
      "Completed:  25000\n"
     ]
    }
   ],
   "source": [
    "convert_reviews_to_ids(data, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1556, 1110,   41, 3814, 3410,    0, 1534,    0, 1864, 5025, 6479,\n",
       "       1556,    0, 1534, 1110, 2404, 1110, 3814,    0, 2159, 5918, 1110,\n",
       "          0, 3880,   41, 5025, 1993,    0,    7, 5025, 1911, 1110,    7,\n",
       "       1968, 3524,    0, 1556, 4868, 4868, 1534, 2159, 1534,    0,    7,\n",
       "       3814,    0, 1110, 1864, 1534, 2159,    7, 2159,   41, 1864,    0,\n",
       "          7, 2159, 1993, 4868, 1534, 3420, 5918, 1110, 1911, 1110,    0,\n",
       "       1556, 6479, 2159,    0, 1534, 1110, 1911,   41, 4868, 6479, 1534,\n",
       "       5025, 3524,    0, 4868, 3420, 1911,    7, 5918,    0, 5918,    7,\n",
       "       1534,    0,    7,    0, 3420, 4868,   41, 3814, 2159,    0, 5140,\n",
       "       5918, 1110, 3814,    0, 1864, 5025,    7,   41, 1993,   41, 3814,\n",
       "       3410,    0, 1968, 4868, 3814, 2159,    0, 3410, 4868,    0, 2159,\n",
       "       5918, 1110, 1911, 1110,    0, 3410,   41, 1911, 5025,    0, 1534,\n",
       "       3420,   41, 1864, 1110,    0, 5140, 4868, 1911, 5025, 1968,    0,\n",
       "       1534, 6479, 1968, 1968, 1110, 3814, 5025, 3524,    0, 1968, 4868,\n",
       "       1110, 1534, 3814, 2159,    0, 1534, 1110, 1110, 1993,    0, 2159,\n",
       "       4868,    0, 1556, 1110,    0,    7, 5025, 5025,    0, 2159, 5918,\n",
       "          7, 2159,    0, 1556,    7, 1968,    0,   41,    0, 2159,    7,\n",
       "       4652, 1110,    0, 1993, 3524,    0, 1993, 4868, 3814, 1110, 3524,\n",
       "          0, 1110, 5025, 1534, 1110, 5140, 5918, 1110, 1911, 1110,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_ids[19825]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_ids = np.load('idsMatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 250)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[174943,    152,     14, ...,      0,      0,      0],\n",
       "       [ 26494,     46, 399999, ...,   2153,    144,      7],\n",
       "       [  6520, 399999,     21, ...,      0,      0,      0],\n",
       "       [    37,     14,   2407, ...,      0,      0,      0],\n",
       "       [    37,     14,     36, ...,      0,      0,      0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = review_ids\n",
    "y_output = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(words)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is easily the most underrated film inn the brooks cannon sure its flawed it does not give a realistic view of homelessness unlike say how citizen kane gave a realistic view of lounge singers or titanic gave a realistic view of italians you idiots many of the jokes fall flat but still this film is very lovable in a way many comedies are not and to pull that off in a story about some of the most traditionally reviled members of society is truly impressive its not the fisher king but its not crap either my only complaint is that brooks should have cast someone else in the lead i love mel as a director and writer not so much as a lead',\n",
       " 'this is not the typical mel brooks film it was much less slapstick than most of his movies and actually had a plot that was followable leslie ann warren made the movie she is such a fantastic underrated actress there were some moments that could have been fleshed out a bit more and some scenes that could probably have been cut to make the room to do so but all in all this is worth the price to rent and see it the acting was good overall brooks himself did a good job without his characteristic speaking to directly to the audience again warren was the best actor in the movie but fume and sailor both played their parts well']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    37,     14,   2407, 201534,     96,  37314,    319,   7158,\n",
       "        201534,   6469,   8828,   1085,     47,   9703,     20,    260,\n",
       "            36,    455,      7,   7284,   1139,      3,  26494,   2633,\n",
       "           203,    197,   3941,  12739,    646,      7,   7284,   1139,\n",
       "             3,  11990,   7792,     46,  12608,    646,      7,   7284,\n",
       "          1139,      3,   8593,     81,  36381,    109,      3, 201534,\n",
       "          8735,    807,   2983,     34,    149,     37,    319,     14,\n",
       "           191,  31906,      6,      7,    179,    109,  15402,     32,\n",
       "            36,      5,      4,   2933,     12,    138,      6,      7,\n",
       "           523,     59,     77,      3, 201534,     96,   4246,  30006,\n",
       "           235,      3,    908,     14,   4702,   4571,     47,     36,\n",
       "        201534,   6429,    691,     34,     47,     36,  35404,    900,\n",
       "           192,     91,   4499,     14,     12,   6469,    189,     33,\n",
       "          1784,   1318,   1726,      6, 201534,    410,     41,    835,\n",
       "         10464,     19,      7,    369,      5,   1541,     36,    100,\n",
       "           181,     19,      7,    410,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0],\n",
       "       [    37,     14,     36, 201534,   3682,  10464,   6469,    319,\n",
       "            20,     15,    181,    440,  32736,     73,     96,      3,\n",
       "            26,   2459,      5,   1403,     40,      7,   2219,     12,\n",
       "            15, 399999,   8900,   5141,   4620,    116, 201534,   1005,\n",
       "            67,     14,    125,      7,   7872, 344179,   2890,     63,\n",
       "            35,     77,   4039,     12,     94,     33,     51,  47268,\n",
       "            66,      7,   1594,     56,      5,     77,   3468,     12,\n",
       "            94,    965,     33,     51,    611,      4,    159, 201534,\n",
       "           927,      4,     88,    100,     34,     64,      6,     64,\n",
       "            37,     14,   1089, 201534,    626,      4,   6046,      5,\n",
       "           253,     20, 201534,   2050,     15,    219,   1250,   6469,\n",
       "           670,    119,      7,    219,    664,    296,     26,   8853,\n",
       "          1354,      4,   1823,      4, 201534,   2052,    378,   4620,\n",
       "            15, 201534,    254,   2018,      6, 201534,   1005,     34,\n",
       "        399999,      5, 399999,    150,    334,     44,   1044,    143,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(x_data)))\n",
    "\n",
    "x_shuffled = x_data[shuffle_indices]\n",
    "y_shuffled = y_output[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = 5000\n",
    "TOTAL_DATA = 6000\n",
    "\n",
    "train_data = x_shuffled[:TRAIN_DATA]\n",
    "train_target = y_shuffled[:TRAIN_DATA]\n",
    "\n",
    "test_data = x_shuffled[TRAIN_DATA:TOTAL_DATA]\n",
    "test_target = y_shuffled[TRAIN_DATA:TOTAL_DATA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.int32, [None, MAX_SEQUENCE_LENGTH])\n",
    "y = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 25\n",
    "embedding_size = 50\n",
    "max_label = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_embeddings = np.load('wordVectors.npy')\n",
    "embeddings = tf.nn.embedding_lookup(saved_embeddings, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 50)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(?, 250, 50) dtype=float32>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(embedding_size)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell = lstmCell, output_keep_prob = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (encoding, _) = tf.nn.dynamic_rnn(lstmCell, embeddings, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 50) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(encoding, max_label, activation = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = y)\n",
    "loss = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.equal(tf.argmax(logits, 1), tf.cast(y, tf.int64))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Test Loss: 0.7, Test Accuracy: 0.501\n",
      "Epoch: 2, Test Loss: 0.69, Test Accuracy: 0.505\n",
      "Epoch: 3, Test Loss: 0.67, Test Accuracy: 0.547\n",
      "Epoch: 4, Test Loss: 0.5, Test Accuracy: 0.776\n",
      "Epoch: 5, Test Loss: 0.55, Test Accuracy: 0.77\n",
      "Epoch: 6, Test Loss: 0.56, Test Accuracy: 0.756\n",
      "Epoch: 7, Test Loss: 0.55, Test Accuracy: 0.775\n",
      "Epoch: 8, Test Loss: 0.62, Test Accuracy: 0.758\n",
      "Epoch: 9, Test Loss: 0.62, Test Accuracy: 0.762\n",
      "Epoch: 10, Test Loss: 0.69, Test Accuracy: 0.775\n",
      "Epoch: 11, Test Loss: 0.68, Test Accuracy: 0.779\n",
      "Epoch: 12, Test Loss: 0.77, Test Accuracy: 0.768\n",
      "Epoch: 13, Test Loss: 0.8, Test Accuracy: 0.772\n",
      "Epoch: 14, Test Loss: 0.85, Test Accuracy: 0.775\n",
      "Epoch: 15, Test Loss: 1.1, Test Accuracy: 0.742\n",
      "Epoch: 16, Test Loss: 1.0, Test Accuracy: 0.75\n",
      "Epoch: 17, Test Loss: 1.1, Test Accuracy: 0.752\n",
      "Epoch: 18, Test Loss: 1.0, Test Accuracy: 0.75\n",
      "Epoch: 19, Test Loss: 1.0, Test Accuracy: 0.771\n",
      "Epoch: 20, Test Loss: 1.1, Test Accuracy: 0.757\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        num_batches = int(len(train_data) // batch_size) + 1\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            min_ix = i * batch_size\n",
    "            max_ix = np.min([len(train_data), ((i+1) * batch_size)])\n",
    "            \n",
    "            x_train_batch = train_data[min_ix:max_ix]\n",
    "            y_train_batch = train_target[min_ix:max_ix]\n",
    "            \n",
    "            train_dict = {x: x_train_batch, y:y_train_batch}\n",
    "            session.run(train_step, feed_dict = train_dict)\n",
    "            \n",
    "            train_loss, train_acc = session.run([loss, accuracy], feed_dict = train_dict)\n",
    "        test_dict = {x: test_data, y: test_target}\n",
    "        \n",
    "        test_loss, test_acc = session.run([loss, accuracy], feed_dict = test_dict)\n",
    "        \n",
    "        print('Epoch: {}, Test Loss: {:.2}, Test Accuracy: {:.5}'.format (epoch + 1, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
